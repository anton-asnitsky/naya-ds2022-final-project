{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a438196",
   "metadata": {
    "papermill": {
     "duration": 0.006227,
     "end_time": "2023-03-17T07:58:23.915933",
     "exception": false,
     "start_time": "2023-03-17T07:58:23.909706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ed79b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T07:58:23.927949Z",
     "iopub.status.busy": "2023-03-17T07:58:23.927431Z",
     "iopub.status.idle": "2023-03-17T07:58:31.623736Z",
     "shell.execute_reply": "2023-03-17T07:58:31.622660Z"
    },
    "papermill": {
     "duration": 7.705514,
     "end_time": "2023-03-17T07:58:31.626556",
     "exception": false,
     "start_time": "2023-03-17T07:58:23.921042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "annotations = \"../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\"\n",
    "images = \"../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\"\n",
    "df = pd.read_csv(\"../input/face-mask-detection-dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/face-mask-detection-dataset/submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901512d",
   "metadata": {
    "papermill": {
     "duration": 0.003188,
     "end_time": "2023-03-17T07:58:31.633587",
     "exception": false,
     "start_time": "2023-03-17T07:58:31.630399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load SSD Face Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d14c791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T07:58:31.641766Z",
     "iopub.status.busy": "2023-03-17T07:58:31.641442Z",
     "iopub.status.idle": "2023-03-17T07:58:32.051517Z",
     "shell.execute_reply": "2023-03-17T07:58:32.050514Z"
    },
    "papermill": {
     "duration": 0.41729,
     "end_time": "2023-03-17T07:58:32.054334",
     "exception": false,
     "start_time": "2023-03-17T07:58:31.637044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvNet = cv2.dnn.readNetFromCaffe('../input/caffe-face-detector-opencv-pretrained-model/architecture.txt','../input/caffe-face-detector-opencv-pretrained-model/weights.caffemodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a7981",
   "metadata": {
    "papermill": {
     "duration": 0.003265,
     "end_time": "2023-03-17T07:58:32.061513",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.058248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191e84d",
   "metadata": {
    "papermill": {
     "duration": 0.003115,
     "end_time": "2023-03-17T07:58:32.068264",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.065149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. getJSON Function fetches the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1002417c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T07:58:32.077294Z",
     "iopub.status.busy": "2023-03-17T07:58:32.076350Z",
     "iopub.status.idle": "2023-03-17T07:58:32.081678Z",
     "shell.execute_reply": "2023-03-17T07:58:32.080709Z"
    },
    "papermill": {
     "duration": 0.012343,
     "end_time": "2023-03-17T07:58:32.084035",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.071692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getJSON(filePathandName):\n",
    "    with open(filePathandName,'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46af56",
   "metadata": {
    "papermill": {
     "duration": 0.003056,
     "end_time": "2023-03-17T07:58:32.090568",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.087512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. Gamma correction is a nonlinear operation used to encode and decode luminance values in video or still image systems. It is used to instill some light in the image. If gamma < 1, image will shift towards darker end of the spectrum and when gamma > 1, there will be more light in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f91399b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T07:58:32.098809Z",
     "iopub.status.busy": "2023-03-17T07:58:32.098515Z",
     "iopub.status.idle": "2023-03-17T07:58:32.103754Z",
     "shell.execute_reply": "2023-03-17T07:58:32.102710Z"
    },
    "papermill": {
     "duration": 0.012312,
     "end_time": "2023-03-17T07:58:32.106207",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.093895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)])\n",
    "    return cv2.LUT(image.astype(np.uint8), table.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92186a",
   "metadata": {
    "papermill": {
     "duration": 0.003246,
     "end_time": "2023-03-17T07:58:32.112714",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.109468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8978af",
   "metadata": {
    "papermill": {
     "duration": 0.003195,
     "end_time": "2023-03-17T07:58:32.119555",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.116360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When we're lookong into training JSON data, we can find out the next:\n",
    "* Anntoations fiels holds data about faces as a coorsinates of rectagular area\n",
    "* Also each annotation holds name of the class, We;re interested in **\"face_with_mask\"** and **\"face_no_mask\"** classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88c998",
   "metadata": {
    "papermill": {
     "duration": 0.00323,
     "end_time": "2023-03-17T07:58:32.125998",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.122768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets' see sample data from training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945a8f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T07:58:32.134124Z",
     "iopub.status.busy": "2023-03-17T07:58:32.133804Z",
     "iopub.status.idle": "2023-03-17T07:59:09.716843Z",
     "shell.execute_reply": "2023-03-17T07:59:09.715697Z"
    },
    "papermill": {
     "duration": 37.591141,
     "end_time": "2023-03-17T07:59:09.720702",
     "exception": false,
     "start_time": "2023-03-17T07:58:32.129561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FileName': '3758.png',\n",
       " 'NumOfAnno': 2,\n",
       " 'Annotations': [{'isProtected': False,\n",
       "   'ID': 217843115901993120,\n",
       "   'BoundingBox': [112, 4, 455, 441],\n",
       "   'classname': 'face_with_mask',\n",
       "   'Confidence': 1,\n",
       "   'Attributes': {}},\n",
       "  {'isProtected': False,\n",
       "   'ID': 12530598208497002,\n",
       "   'BoundingBox': [113, 237, 345, 440],\n",
       "   'classname': 'mask_colorful',\n",
       "   'Confidence': 1,\n",
       "   'Attributes': {}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "for i in os.listdir(annotations):\n",
    "    files.append(getJSON(os.path.join(annotations,i)))\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd1abe",
   "metadata": {
    "papermill": {
     "duration": 0.003341,
     "end_time": "2023-03-17T07:59:09.727506",
     "exception": false,
     "start_time": "2023-03-17T07:59:09.724165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Now we'll arrange the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53caf53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T07:59:09.736625Z",
     "iopub.status.busy": "2023-03-17T07:59:09.735630Z",
     "iopub.status.idle": "2023-03-17T07:59:09.764746Z",
     "shell.execute_reply": "2023-03-17T07:59:09.763636Z"
    },
    "papermill": {
     "duration": 0.035906,
     "end_time": "2023-03-17T07:59:09.766995",
     "exception": false,
     "start_time": "2023-03-17T07:59:09.731089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>69</td>\n",
       "      <td>126</td>\n",
       "      <td>294</td>\n",
       "      <td>392</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>505</td>\n",
       "      <td>10</td>\n",
       "      <td>723</td>\n",
       "      <td>283</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>75</td>\n",
       "      <td>252</td>\n",
       "      <td>264</td>\n",
       "      <td>390</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>521</td>\n",
       "      <td>136</td>\n",
       "      <td>711</td>\n",
       "      <td>277</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6098.jpg</td>\n",
       "      <td>360</td>\n",
       "      <td>85</td>\n",
       "      <td>728</td>\n",
       "      <td>653</td>\n",
       "      <td>face_no_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   x1   x2   y1   y2       classname\n",
       "0  2756.png   69  126  294  392  face_with_mask\n",
       "1  2756.png  505   10  723  283  face_with_mask\n",
       "2  2756.png   75  252  264  390   mask_colorful\n",
       "3  2756.png  521  136  711  277   mask_colorful\n",
       "4  6098.jpg  360   85  728  653    face_no_mask"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/face-mask-detection-dataset/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cddd7b",
   "metadata": {
    "papermill": {
     "duration": 0.003364,
     "end_time": "2023-03-17T07:59:09.774253",
     "exception": false,
     "start_time": "2023-03-17T07:59:09.770889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* We'll use **mask label** and **non_mask label** to extract bounding box data from json files.\n",
    "* We'll store faces from any particular image in the **train** list along with its label for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ddac653",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T07:59:09.782920Z",
     "iopub.status.busy": "2023-03-17T07:59:09.782593Z",
     "iopub.status.idle": "2023-03-17T08:01:15.460761Z",
     "shell.execute_reply": "2023-03-17T08:01:15.459724Z"
    },
    "papermill": {
     "duration": 125.688501,
     "end_time": "2023-03-17T08:01:15.466470",
     "exception": false,
     "start_time": "2023-03-17T07:59:09.777969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "img_size = 124\n",
    "mask = ['face_with_mask']\n",
    "non_mask = [\"face_no_mask\"]\n",
    "labels={'mask':0,'without mask':1}\n",
    "for i in df[\"name\"].unique():\n",
    "    f = i+\".json\"\n",
    "    for j in getJSON(os.path.join(annotations,f)).get(\"Annotations\"):\n",
    "        if j[\"classname\"] in mask:\n",
    "            x,y,w,h = j[\"BoundingBox\"]\n",
    "            img = cv2.imread(os.path.join(images,i),1)\n",
    "            img = img[y:h,x:w]\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            train.append([img,labels[\"mask\"]])\n",
    "        if j[\"classname\"] in non_mask:\n",
    "            x,y,w,h = j[\"BoundingBox\"]\n",
    "            img = cv2.imread(os.path.join(images,i),1)\n",
    "            img = img[y:h,x:w]\n",
    "            img = cv2.resize(img,(img_size,img_size))    \n",
    "            train.append([img,labels[\"without mask\"]])\n",
    "random.shuffle(train)  \n",
    "len(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 183.802232,
   "end_time": "2023-03-17T08:01:18.725448",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-17T07:58:14.923216",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
